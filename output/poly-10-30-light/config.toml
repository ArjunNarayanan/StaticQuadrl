# BASELINE MODEL

[evaluator]
  num_evaluation_trajectories = 100

[policy]
  input_channels = 216
  hidden_channels = 128
  num_hidden_layers = 3
  output_channels = 5

[environment]
  min_polygon_degree = 10
  max_polygon_degree = 30
  max_actions_factor = 3
  quad_alg = "catmull-clark"
  cleanup = true
  round_desired_degree = true

[PPO]
  epsilon = 0.05
  discount = 1.0
  minibatch_size = 128
  episodes_per_iteration = 100
  epochs_per_iteration = 10
  number_of_iterations = 2000
  entropy = 0.005

[optimizer]
  lr = 1e-4
  decay = 0.98
  decay_step = 5000
  clip = 1e-2
